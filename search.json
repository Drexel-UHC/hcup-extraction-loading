[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HCUP Resource at the UHC",
    "section": "",
    "text": "The Healthcare Cost and Utilization Project (HCUP) includes the largest collection of longitudinal hospital care data in the United States."
  },
  {
    "objectID": "index.html#databases",
    "href": "index.html#databases",
    "title": "HCUP Resource at the UHC",
    "section": "Databases",
    "text": "Databases\nHCUP has both nationwide HCUP and state-specific HCUP databases.\n\nNationwide\n\nNIS - National Inpatient Sample\nKID - Kids’ Inpatient Database\nNASS Nationwide Ambulatory Surgery Sample\nNEDS - Nationwide Emergency Department Sample\nNRD - Nationwide Readmissions Database\n\nState-specific\n\nSID - State Inpatient Databases\nSASD - State Ambulatory Surgery and Services Databases\nSEDD - State Emergency Department Databases"
  },
  {
    "objectID": "index.html#what-is-hcup",
    "href": "index.html#what-is-hcup",
    "title": "HCUP Resource at the UHC",
    "section": "What is HCUP",
    "text": "What is HCUP\n\nThe Healthcare Cost and Utilization Project (HCUP) includes the largest collection of longitudinal hospital care data in the United States."
  },
  {
    "objectID": "pages/manuals/parquet/index.html",
    "href": "pages/manuals/parquet/index.html",
    "title": "Parquet",
    "section": "",
    "text": "Apache Parquet is a popular column storage file format common used to efficiently store large datasets and has the .parquet extension. Key features of parquet are:\nThe later two points make it alternative to CSV in that parquet workflows have efficient storage (much smaller file sizes than CSV), accessible metadata for columns and efficient queries.\nThis blog will use a few packages.Lets load them first\nFirst lets put together some data to play around with. We’ll start with the Palmer’s penguins data then copy it a thousand times to make a rather large table.\nA glimpse of the data shows it has 344,000 rows with 8 columns.\nBelow we conduct some CSV vs Parquet experiments"
  },
  {
    "objectID": "pages/manuals/parquet/index.html#file-sizes",
    "href": "pages/manuals/parquet/index.html#file-sizes",
    "title": "Parquet",
    "section": "File Sizes",
    "text": "File Sizes\nLets do our first experiemnt. If we were to store this piece of data somewhere how large would it be.\n\n# Create a temporary file for the output\nwrite_parquet(big_penguins, sink = 'processed/test.parquet')\nwrite_csv_arrow(big_penguins, sink = 'processed/test.csv')\n\n# get file sizes\ntibble(format = c(\"csv\",\"parquet\"),\n       size_bytes = c(file.size('processed/test.csv'),\n                      file.size('processed/test.parquet'))) %>% \n  reactable()\n\n\n\n\n\n\nWe can see the parquet format is only 88 KB in size compared to the 16,760 KB CSV; in this example CSV storage take up 192 more space compared to parquet. If we were storing things on the cloud, in this case, parquet format would be almost 200 times cheaper!"
  },
  {
    "objectID": "pages/manuals/parquet/index.html#queries",
    "href": "pages/manuals/parquet/index.html#queries",
    "title": "Parquet",
    "section": "Queries",
    "text": "Queries\nParquets are the defaco standard for dat"
  }
]